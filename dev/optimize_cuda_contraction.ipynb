{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac79abc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T12:24:35.475000+02:00",
     "start_time": "2021-10-23T10:24:33.591Z"
    }
   },
   "outputs": [],
   "source": [
    "# necessary when running on compute node over NFS\n",
    "ENV[\"JULIA_REVISE_POLL\"] = \"1\"\n",
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c3cb5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T12:24:37.655000+02:00",
     "start_time": "2021-10-23T10:24:34.777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/.julia/dev/SymArrays/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "pkg\"activate ..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a8cb8ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:42:35.310000+02:00",
     "start_time": "2021-10-23T11:42:35.188Z"
    }
   },
   "outputs": [],
   "source": [
    "using SymArrays\n",
    "using SymArrays: @cuindex, cudims, SymIndexIter, ind2sub_symgrp, symgrp_sortedsub2ind\n",
    "using TensorOperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f4276e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:33:05.099000+02:00",
     "start_time": "2021-10-23T11:33:04.969Z"
    }
   },
   "outputs": [],
   "source": [
    "using CUDA\n",
    "using MacroTools\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee340eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:57:47.211000+02:00",
     "start_time": "2021-10-23T11:57:46.948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuda_contraction_kernel_code (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cuda_contraction_kernel_code(Nsymres)\n",
    "    # calculate res[iA1,iA3,iS1,iSm2,iS3] = ∑_iA2 A[iA1,iA2,iA3] * S[iS1,iS2,iS3]\n",
    "    # where iSm2 = (i1,i2,...,iNsymres) and iS2 = sorted(iA2,i1,i2,i3...,iNsymres)\n",
    "    code = quote\n",
    "        I = @cuindex(res)\n",
    "        iA1,iA3,iS1,iSm2,iS3 = I\n",
    "        ISm2 = ind2sub_symgrp(SI, iSm2)\n",
    "        res[I...] = zero(eltype(res))\n",
    "    end\n",
    "    for n = 0:Nsymres\n",
    "        iAstart = n==0 ? 1 : :(ISm2[$n]+1)\n",
    "        iAend = n<Nsymres ? :(ISm2[$(n+1)]) : :(size(A,2))\n",
    "        iprev = [:( ISm2[$i] ) for i=1:n]\n",
    "        ipost = [:( ISm2[$i] ) for i=n+1:Nsymres]\n",
    "        cc = :( for iA2 = $iAstart:$iAend\n",
    "                    iS2 = symgrp_sortedsub2ind($(iprev...),iA2,$(ipost...))\n",
    "                    res[I...] += A[iA1,iA2,iA3]*S[iS1,iS2,iS3]\n",
    "                end)\n",
    "        push!(code.args,cc)\n",
    "    end\n",
    "    push!(code.args,:(return))\n",
    "    :( @inbounds $code )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb40d5f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:32:44.968000+02:00",
     "start_time": "2021-10-23T11:32:44.875Z"
    }
   },
   "outputs": [],
   "source": [
    "@generated function SymArrays.cuda_contraction_kernel(res, A, S, SI::SymIndexIter{Nsymres}) where {Nsymres}\n",
    "    cuda_contraction_kernel_code(Nsymres)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa3b6b17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:39:38.959000+02:00",
     "start_time": "2021-10-23T11:39:36.574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@cuda [kwargs...] func(args...)\n",
       "\\end{verbatim}\n",
       "High-level interface for executing code on a GPU. The \\texttt{@cuda} macro should prefix a call, with \\texttt{func} a callable function or object that should return nothing. It will be compiled to a CUDA function upon first use, and to a certain extent arguments will be converted and managed automatically using \\texttt{cudaconvert}. Finally, a call to \\texttt{cudacall} is performed, scheduling a kernel launch on the current CUDA context.\n",
       "\n",
       "Several keyword arguments are supported that influence the behavior of \\texttt{@cuda}.\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{launch}: whether to launch this kernel, defaults to \\texttt{true}. If \\texttt{false} the returned kernel object should be launched by calling it and passing arguments again.\n",
       "\n",
       "\n",
       "\\item \\texttt{dynamic}: use dynamic parallelism to launch device-side kernels, defaults to \\texttt{false}.\n",
       "\n",
       "\n",
       "\\item arguments that influence kernel compilation: see \\href{@ref}{\\texttt{cufunction}} and \\href{@ref}{\\texttt{dynamic\\_cufunction}}\n",
       "\n",
       "\n",
       "\\item arguments that influence kernel launch: see \\href{@ref}{\\texttt{CUDA.HostKernel}} and \\href{@ref}{\\texttt{CUDA.DeviceKernel}}\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "@cuda [kwargs...] func(args...)\n",
       "```\n",
       "\n",
       "High-level interface for executing code on a GPU. The `@cuda` macro should prefix a call, with `func` a callable function or object that should return nothing. It will be compiled to a CUDA function upon first use, and to a certain extent arguments will be converted and managed automatically using `cudaconvert`. Finally, a call to `cudacall` is performed, scheduling a kernel launch on the current CUDA context.\n",
       "\n",
       "Several keyword arguments are supported that influence the behavior of `@cuda`.\n",
       "\n",
       "  * `launch`: whether to launch this kernel, defaults to `true`. If `false` the returned kernel object should be launched by calling it and passing arguments again.\n",
       "  * `dynamic`: use dynamic parallelism to launch device-side kernels, defaults to `false`.\n",
       "  * arguments that influence kernel compilation: see [`cufunction`](@ref) and [`dynamic_cufunction`](@ref)\n",
       "  * arguments that influence kernel launch: see [`CUDA.HostKernel`](@ref) and [`CUDA.DeviceKernel`](@ref)\n"
      ],
      "text/plain": [
       "  \u001b[38;5;208m@\u001b[0m\u001b[38;5;208mcuda\u001b[0m \u001b[0m\u001b[39m[\u001b[0m\u001b[39mkwargs\u001b[0m\u001b[38;5;197m...\u001b[0m\u001b[39m]\u001b[0m \u001b[0m\u001b[38;5;81mfunc\u001b[0m(\u001b[0m\u001b[39margs\u001b[0m\u001b[38;5;197m...\u001b[0m\u001b[39m)\u001b[0m\u001b[39m\u001b[0m\n",
       "\n",
       "\n",
       "  High-level interface for executing code on a GPU. The \u001b[36m@cuda\u001b[39m macro should\n",
       "  prefix a call, with \u001b[36mfunc\u001b[39m a callable function or object that should return\n",
       "  nothing. It will be compiled to a CUDA function upon first use, and to a\n",
       "  certain extent arguments will be converted and managed automatically using\n",
       "  \u001b[36mcudaconvert\u001b[39m. Finally, a call to \u001b[36mcudacall\u001b[39m is performed, scheduling a kernel\n",
       "  launch on the current CUDA context.\n",
       "\n",
       "  Several keyword arguments are supported that influence the behavior of\n",
       "  \u001b[36m@cuda\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mlaunch\u001b[39m: whether to launch this kernel, defaults to \u001b[36mtrue\u001b[39m. If \u001b[36mfalse\u001b[39m\n",
       "       the returned kernel object should be launched by calling it and\n",
       "       passing arguments again.\n",
       "\n",
       "    •  \u001b[36mdynamic\u001b[39m: use dynamic parallelism to launch device-side kernels,\n",
       "       defaults to \u001b[36mfalse\u001b[39m.\n",
       "\n",
       "    •  arguments that influence kernel compilation: see \u001b[36mcufunction\u001b[39m and\n",
       "       \u001b[36mdynamic_cufunction\u001b[39m\n",
       "\n",
       "    •  arguments that influence kernel launch: see \u001b[36mCUDA.HostKernel\u001b[39m and\n",
       "       \u001b[36mCUDA.DeviceKernel\u001b[39m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc60df52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:32:47.942000+02:00",
     "start_time": "2021-10-23T11:32:45.835Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 300\n",
    "A = CUDA.rand(Float64,N)\n",
    "S = SymArray{(3,),Float64}(CuArray,N,N,N);\n",
    "S.data .= 1:length(S)\n",
    "B = CuArray(collect(collect(S)))\n",
    "C1 = SymArray{(2,),Float64}(CuArray,N,N)\n",
    "C2 = copy(C1)\n",
    "@tensor C3[j,k] := A[i]*B[i,j,k]\n",
    "contract!(C1,A,S,Val(1),Val(1))\n",
    "# this is the \"hand-written\" version where A has to be 1D\n",
    "#contract!(C2,A,S,Val(1))\n",
    "#@assert C1 ≈ C2\n",
    "@assert collect(C1) ≈ collect(C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cbd42",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-23T11:43:52.412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  953.334 μs (38 allocations: 17.23 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime CUDA.@sync @tensor C3[j,k] = A[i]*B[i,j,k]\n",
    "@btime CUDA.@sync contract!(C1,A,S,Val(1),Val(1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b643fbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:57:45.891000+02:00",
     "start_time": "2021-10-23T11:57:45.762Z"
    }
   },
   "outputs": [],
   "source": [
    "function SymArrays.contract_symindex!(res::CuArray{TU,5}, A::CuArray{T,3}, ::Val{sizeA13unit}, S::CuArray{U,3}, ::Val{sizeS13unit}, ::Val{Nsym}) where {T,U,TU,sizeA13unit,sizeS13unit,Nsym}\n",
    "    blk, thr = cudims(res)\n",
    "    SI = SymIndexIter(Nsym-1,size(A,2))\n",
    "    #@cuda blocks=blk threads=thr cuda_contraction_kernel(res,A,S,SI)\n",
    "    kernel = @cuda launch=false cuda_contraction_kernel(res,A,S,SI)\n",
    "    config = CUDA.launch_configuration(kernel.fun)\n",
    "    # @show config.threads, thr\n",
    "    # @show config.blocks, blk\n",
    "    threads = min(length(res), config.threads)\n",
    "    blocks = cld(length(res), threads)\n",
    "    kernel(res,A,S,SI; threads, blocks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e9383dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:57:47.211000+02:00",
     "start_time": "2021-10-23T11:57:46.948Z"
    }
   },
   "outputs": [],
   "source": [
    "contract!(C1,A,S,Val(1),Val(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0192060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:57:59.851000+02:00",
     "start_time": "2021-10-23T11:57:48.224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.617 ms (28 allocations: 1.62 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime CUDA.@sync contract!(C1,A,S,Val(1),Val(1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c3702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "node Julia 1 GPUs",
   "language": "",
   "name": "compute_node_julia_1gpu"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
